{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895f3c55",
   "metadata": {},
   "source": [
    "# IPIN 2025 Flowcean Hands-on Session\n",
    "\n",
    "This is the tutorial file for the IPIN 2025 workshop. In this Jupyter notebook, we will go through the steps of training machine learning models with the Flowcean framework.\n",
    "\n",
    "In this example we are using the package [turtlesim](http://wiki.ros.org/turtlesim) is a tool made for teaching the Robot Operating System (ROS). This example trains models to predict the next pose of the turtle $\\textbf{x}_{k+1}$ based on the current pose $\\textbf{x}_{k}$ and velocity commands $\\textbf{u}_{k}$.\n",
    "\n",
    "![Motion model for turtlesim](./images/turtlesim_model.svg)\n",
    "\n",
    "It uses ROS bag data recorded from turtlesim, processes it into supervised samples, learns multiple models, evaluates them with several metrics, and plots predictions versus ground truth.\n",
    "\n",
    "![Turtlesim simulation](./images/turtlesim.png)\n",
    "\n",
    "A config file is used to specify paths and parameters for the training run. See `config.yaml` for details.\n",
    "The example expects two ROS bag directories in the config:\n",
    "\n",
    "- Training: `rosbag.training_path`\n",
    "- Evaluation: `rosbag.evaluation_path`\n",
    "\n",
    "Topics used:\n",
    "\n",
    "- `/turtle1/cmd_vel` with fields `linear.x`, `angular.z`\n",
    "- `/turtle1/pose` with fields `x`, `y`, `theta`\n",
    "\n",
    "`/turtle1/cmd_vel` is the desired velocity command for the turtle. It specifies the linear and angular velocities that the turtle should follow. `/turtle1/pose` provides the actual position and orientation of the turtle in the simulation environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919276d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports we will need\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03844bf",
   "metadata": {},
   "source": [
    "## Section 1 : Load and Prepare the Training Data\n",
    "We will use the turtlesim example dataset for this tutorial. The dataset is a ROS2 bag file that contains the pose and velocity of a turtle in the turtlesim simulator. The goal is to predict the next pose of the turtle given its current pose and velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import flowcean and cli\n",
    "import flowcean\n",
    "import flowcean.cli\n",
    "\n",
    "# Import some helper functions for loading ROS data\n",
    "from os import PathLike\n",
    "\n",
    "from _collections_abc import Iterable\n",
    "from flowcean.core.transform import Lambda\n",
    "\n",
    "# import transforms\n",
    "from flowcean.polars import DataFrame, ExplodeTimeSeries, ZeroOrderHold\n",
    "from flowcean.ros import load_rosbag\n",
    "\n",
    "from _helper_functions import shift_in_time\n",
    "\n",
    "# The function below looks for a config.yaml in the current directory\n",
    "# In the config.yaml, we specify settings for our training run \n",
    "config = flowcean.cli.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842384e0",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1.1 Load Rosbags and Choose Inputs\n",
    "\n",
    "First, we need to load the ROS2 bag file and extract the relevant topics and fields. We will use the `load_rosbag` function from the `flowcean.ros` module to do this.\n",
    "\n",
    "The topics and fields we use load are:   \n",
    "```yaml  \n",
    "  - /turtle1/cmd_vel\n",
    "      - linear.x\n",
    "      - angular.z\n",
    "  - /turtle1/pose\n",
    "      - x\n",
    "      - y\n",
    "      - theta\n",
    "```\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Call the load_rosbag function and pass:    \n",
    "  - the bag_path                           \n",
    "  - requires topics and their fields       \n",
    "  - the message_path                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea77fb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Configure the load_rosbag() function below\n",
    "def load_and_process_rosbag(\n",
    "    path: str | PathLike,\n",
    "    message_paths: Iterable[str | PathLike] | None = None,\n",
    ") -> DataFrame:\n",
    "    logger.info(\"Loading rosbag from: %s\", path)\n",
    "\n",
    "    rosbag = load_rosbag(\n",
    "        # TODO: TASK 1.1\n",
    "    )\n",
    "    return (\n",
    "        DataFrame(rosbag) \n",
    "    )\n",
    "\n",
    "# using our loaded config we want to create training and evaluation samples\n",
    "samples_train = load_and_process_rosbag(\n",
    "    config.rosbag.training_path,\n",
    "    config.rosbag.message_paths,\n",
    ")\n",
    "samples_eval = load_and_process_rosbag(\n",
    "    config.rosbag.evaluation_path,\n",
    "    config.rosbag.message_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ecbf8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "    rosbag = load_rosbag(\n",
    "        path=path,\n",
    "        topics={\n",
    "            \"/turtle1/cmd_vel\": [\n",
    "                \"linear.x\",\n",
    "                \"angular.z\",\n",
    "            ],\n",
    "            \"/turtle1/pose\": [\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"theta\",\n",
    "            ],\n",
    "        },\n",
    "        message_paths=message_paths,\n",
    "    )   \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f8a7e",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1.2 Create Training Data Frame\n",
    "\n",
    "Now that we have loaded the ROS2 bag file, we need to create a training data frame that contains the input features and the target variable. The input features are the current pose and velocity of the turtle, and the target variable is the next pose of the turtle.\n",
    "\n",
    "The following table shows how the values of the current pose vector $\\textbf{x}_{k}$ are shifted to form the next pose vector $\\textbf{x}_{k+1}$. The next pose vector is the supervised target we want to predict.\n",
    "\n",
    "| $ \\textbf{x}_{k} $ | $ \\textbf{u}_{k} $     | $ \\textbf{x}_{k+1} $   |\n",
    "|----------------------|----------------------|----------------------  |\n",
    "| [0, 0, 0]            | [1, 0]               | <span style=\"color:red\">[5, 0, 0]</span>            |\n",
    "| <span style=\"color:red\">[5, 0, 0]</span>          | [0, 1]               | <span style=\"color:green\">[5, 0, 2]</span>          |\n",
    "| <span style=\"color:green\">[5, 0, 2]</span>       | [5, 0]               | [7, 4, 2]            |\n",
    "| ...                    | ...                | ...                    |\n",
    "| [4, 2, 2]     | [0, 0]                | null                    |\n",
    "\n",
    "Note that this results in a null value for the next pose vector in the last row, which is filtered out.\n",
    "We will use the `ZeroOrderHold`, `ExplodeTimeSeries`, and `Lambda` transforms from the `flowcean.polars` module to create the training data frame. The `Lambda` transform can apply arbitrary functions to the data, and we will apply the `shift_in_time` function to shift the current pose vector to form the next pose vector.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Modify the `load_and_process_rosbag` function to create a training data frame with the following steps:\n",
    "- Call the `ZeroOrderHold` Transform:\n",
    "  - our features are our topics\n",
    "  - name the new column \"measurments\"\n",
    "\n",
    "- Chain the `ExplodeTimeSeries` Transform: Apply the `ExplodeTimeSeries` transform to the measurement column\n",
    "\n",
    "- Chain the `Lambda` Transform: pass the function `shift_in_time()`\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    "\n",
    "You can concatenate/chain transforms to a dataframe with the `|` operator.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the return statement below to include the necessary transforms\n",
    "def load_and_process_rosbag(\n",
    "        path: str | PathLike,\n",
    "        message_paths: Iterable[str | PathLike] | None = None,\n",
    "    ) -> DataFrame:\n",
    "    logger.info(\"Loading rosbag from: %s\", path)\n",
    "\n",
    "    rosbag = load_rosbag(\n",
    "        path=path,\n",
    "        message_paths=message_paths,\n",
    "        topics={\n",
    "            \"/turtle1/cmd_vel\": [\n",
    "                \"linear.x\",\n",
    "                \"angular.z\",\n",
    "            ],\n",
    "            \"/turtle1/pose\": [\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"theta\",\n",
    "            ],\n",
    "        },\n",
    "    )\n",
    "    return (\n",
    "        DataFrame(rosbag)\n",
    "        | ZeroOrderHold(\n",
    "            features=[\n",
    "                \"/turtle1/cmd_vel\",\n",
    "                \"/turtle1/pose\",\n",
    "            ],\n",
    "            name=\"measurements\",\n",
    "        )\n",
    "        | ExplodeTimeSeries(\"measurements\")\n",
    "        | Lambda(shift_in_time)\n",
    "    )\n",
    "\n",
    "\n",
    "# using our loaded config we want to create training and evaluation samples\n",
    "samples_train = load_and_process_rosbag(\n",
    "    config.rosbag.training_path,\n",
    "    config.rosbag.message_paths,\n",
    ")\n",
    "samples_eval = load_and_process_rosbag(\n",
    "    config.rosbag.evaluation_path,\n",
    "    config.rosbag.message_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5103304",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "return (\n",
    "    DataFrame(rosbag)\n",
    "    | ZeroOrderHold(\n",
    "        features=[\n",
    "            \"/turtle1/cmd_vel\",\n",
    "            \"/turtle1/pose\",\n",
    "        ],\n",
    "        name=\"measurements\",\n",
    "    )\n",
    "    | ExplodeTimeSeries(\"measurements\")\n",
    "    | Lambda(shift_in_time)\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53475c82",
   "metadata": {},
   "source": [
    "## Section 2 : Select Learners across Libraries \n",
    "\n",
    "Now that we have our training and evaluation samples, we can select learners from different libraries. We will use a `RandomForestRegressor` and a `RegressionTree` from sklearn, a `MultilayerPerceptron` from PyTorch, and an `XGBoostRegressor` from XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load all the learners for our training loop\n",
    "from flowcean.sklearn import RandomForestRegressorLearner, RegressionTree\n",
    "from flowcean.torch import LightningLearner, MultilayerPerceptron\n",
    "from flowcean.xgboost import XGBoostRegressorLearner\n",
    "\n",
    "inputs = [\n",
    "        \"/turtle1/pose/x\",\n",
    "        \"/turtle1/pose/y\",\n",
    "        \"/turtle1/pose/theta\",\n",
    "        \"/turtle1/cmd_vel/linear.x\",\n",
    "        \"/turtle1/cmd_vel/angular.z\",\n",
    "]\n",
    "outputs = [\n",
    "        \"/turtle1/pose/x_next\",\n",
    "        \"/turtle1/pose/y_next\",\n",
    "        \"/turtle1/pose/theta_next\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c2595",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2.1 Learner configuration\n",
    "We will use the configurations defined in the `config.yaml` file to initialize our learners. The configurations are stored in the `config.learners` attribute.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Initialize a regression tree, a random forest, a multilayer perceptron, and a XGBoost learner:\n",
    "   - pass the tree configuration to the regression tree\n",
    "   - pass the forest configuration to the random forest\n",
    "   - pass a multilayer perceptron instance to the lightning learner and pass both their respective configurations\n",
    "   - pass a XGBoost regressor instance to the XGBoost learner\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    "    HINT: We defined our configurations in the config.yaml file.                     \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c18a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and configure the learners below\n",
    "regression_tree = None  # TODO: Task 2.1\n",
    "\n",
    "random_forest = None    # TODO: Task 2.1\n",
    "\n",
    "mlp = None              # TODO: Task 2.1\n",
    "\n",
    "xgb = None              # TODO: Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60be425",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "regression_tree = RegressionTree(\n",
    "    **config.training.tree\n",
    ")\n",
    "\n",
    "random_forest = RandomForestRegressorLearner(\n",
    "    **config.training.forest,\n",
    ")\n",
    "\n",
    "mlp = LightningLearner(\n",
    "    module=MultilayerPerceptron(\n",
    "        learning_rate=config.training.mlp.learning_rate,\n",
    "    ),\n",
    "    batch_size=config.training.mlp.batch_size,\n",
    "    max_epochs=config.training.mlp.max_epochs,\n",
    ")\n",
    "\n",
    "xgb = XGBoostRegressorLearner()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57354b",
   "metadata": {},
   "source": [
    "### Task 2.2 Prepare Sequential Learning\n",
    "We want to train all of our models in a looped fassion. To do this, we need to create a list of our learners.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "   - Create list for the learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6639e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionaries and lists below\n",
    "learners = [\n",
    "    # TODO: Task 2.2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a204f6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "learners = [\n",
    "    regression_tree,\n",
    "    random_forest,\n",
    "    mlp,\n",
    "    xgb,\n",
    "]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf79f6",
   "metadata": {},
   "source": [
    "## Section 3: Training of the Models\n",
    "\n",
    "We will now train our models by looping over the learners dictionary we created in the previous section and apply the `learn_offline strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our learning strategy\n",
    "from flowcean.core import learn_offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91dd18",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Task 3.1 Create a Sequential Learning Loop\n",
    "\n",
    "We will now create a training loop that will train each learner on the training samples. We will store the trained models in a list.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Implement the training loop:\n",
    "  - call the `learn_offline` function and pass the required parameters\n",
    "  - append the trained model to the models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for learner in learners:\n",
    "    logger.info(\"Training model: %s\", learner.name)\n",
    "    model = None  # TODO: Task 3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9191cfe",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "  ```python\n",
    "models = []\n",
    "for learner in learners:\n",
    "    logger.info(\"Training model: %s\", learner.name)\n",
    "    model = learn_offline(\n",
    "        samples_train,\n",
    "        learner,\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    models.append(model)\n",
    "  ```\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594a375",
   "metadata": {},
   "source": [
    "## Section 4 : Evaluation and Model Comparison\n",
    "\n",
    "We will now evaluate our trained models on the evaluation samples. We will use the `evaluate_offline` function from the `flowcean.training` module to do this. We will also compare the performance of the models using the `compare_models` function from the same module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our metrics for comparison\n",
    "from flowcean.sklearn import MeanAbsoluteError, MeanSquaredError, R2Score\n",
    "from custom_metrics.euclidean_distance import MeanEuclideanDistance\n",
    "\n",
    "# import function for model comparison\n",
    "from flowcean.core import evaluate_offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e812e4",
   "metadata": {},
   "source": [
    "### Task 4.1 Chose Metrics for Evaluation\n",
    "\n",
    "We want to evaluate our models using different metrics. We will define a list of metrics that we want to use for evaluation. The metrics we want to use are:\n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- Regression Score (R2Score)\n",
    "- Mean Euclidean Distance\n",
    "\n",
    "**Instructions**   \n",
    "Define a list of metrics that we want to use for evaluation and add the required metrics to a list\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    "    HINT: The euclidean distance requires the columns it should be calculated on.                   \n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07980f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify metrics for evaluation\n",
    "metrics = [\n",
    "    # TODO: 4.1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a53e30",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "metrics = [\n",
    "    MeanAbsoluteError(),\n",
    "    MeanSquaredError(),\n",
    "    R2Score(),\n",
    "    MeanEuclideanDistance(\n",
    "        columns=[\n",
    "            \"/turtle1/pose/x_next\",\n",
    "            \"/turtle1/pose/y_next\",\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de636b99",
   "metadata": {},
   "source": [
    "### Task 4.2 Create an Evaluation Loop\n",
    "\n",
    "We will use the `evaluate_offline` strategy to evaluate each trained model on the evaluation samples. The resulting report object contains the results of all metrics for each model which can be displayed in a table using the `great_table()` method.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Implement the evaluation loop:\n",
    "   - call the evaluate_offline function and pass the required parameters\n",
    "   - store the reports in a dict for later comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = None  # TODO: 4.2\n",
    "report.great_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d3bd3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
    "\n",
    "```python\n",
    "report = evaluate_offline(\n",
    "    models,\n",
    "    environment=samples_eval,\n",
    "    metrics=metrics,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    ")\n",
    "report.great_table()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a8bb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e674663",
   "metadata": {},
   "source": [
    "\n",
    "###  Task 4.3 Select a Model and Visualization  \n",
    "\n",
    "We want to select the best model based on the evaluation reports we created in the previous task. We will also visualize the predictions of the best model against the ground truth using the `predictions_vs_ground_truth` function from the same module. \n",
    "\n",
    " **Instructions**\n",
    "\n",
    "   - Choose the best model based on the evaluation report\n",
    "   - call the `predictions_vs_ground_truth` function and pass the required parameters\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
    " HINT: we can observe and collect samples   \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _helper_functions import plot_predictions_vs_ground_truth\n",
    "\n",
    "best_model = None # TODO: 4.3 \n",
    "best_model = models[0]\n",
    "logger.info(\"Best model: %s\", best_model.name)\n",
    "\n",
    "# Plots are saved under plots/\n",
    "plot_predictions_vs_ground_truth(\n",
    "    samples_eval=samples_eval.observe().collect(),\n",
    "    input_names=inputs,\n",
    "    output_names=outputs,\n",
    "    models=models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf6fc2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Click to see a solution</summary>\n",
    "\n",
    "The best model is the XGBoost model.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393f66b",
   "metadata": {},
   "source": [
    "## Section 5 : Final Task\n",
    "\n",
    "After you completed the tasks, just run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df699c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _helper_functions import surprise\n",
    "\n",
    "surprise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipin-2025-workshop (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
