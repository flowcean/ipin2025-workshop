{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "895f3c55",
      "metadata": {
        "id": "895f3c55"
      },
      "source": [
        "# IPIN 2025 Flowcean Hands-on Session\n",
        "\n",
        "This is the tutorial file for the IPIN 2025 workshop. In this Jupyter notebook, we will go through the steps of training machine learning models using the Flowcean framework.\n",
        "\n",
        "In this example, we use the package [turtlesim](http://wiki.ros.org/turtlesim), a tool designed for teaching the Robot Operating System (ROS). The example trains models to predict the next pose of the turtle, $\\textbf{x}_{k+1}$, based on the current pose $\\textbf{x}_{k}$ and velocity commands $\\textbf{u}_{k}$.  \n",
        "\n",
        "ROS uses _topics_ to communicate between _nodes_. Nodes are processes that perform computations. They can **subscribe** to topics (receive messages from other nodes) or **publish** on topics (send messages to other nodes). In this example, the velocity commands are published to the `/turtle1/cmd_vel` topic by the turtle's teleop node (a node that lets you control the turtle interactively). The turtlesim node receives these velocity commands by subscribing to `/turtle1/cmd_vel` and publishes the turtle's pose to `/turtle1/pose`.\n",
        "\n",
        "![Motion model for turtlesim](https://github.com/flowcean/ipin2025-workshop/blob/main/images/turtlesim_model.svg?raw=1)\n",
        "\n",
        "You can record ROS bag files using the _rosbag_ command-line tool. A ROS bag is a file format for storing ROS message data. It is commonly used for logging data during robot operation, which can later be played back for analysis or testing.\n",
        "The tutorial uses ROS bag data recorded from turtlesim, processes it into supervised samples, trains multiple models, evaluates them using several metrics, and plots predictions versus ground truth.\n",
        "\n",
        "![Turtlesim simulation](https://github.com/flowcean/ipin2025-workshop/blob/main/images/turtlesim.png?raw=1)\n",
        "\n",
        "**Topics used:**\n",
        "\n",
        "- `/turtle1/cmd_vel` with fields `linear.x`, `angular.z`  \n",
        "- `/turtle1/pose` with fields `x`, `y`, `theta`  \n",
        "\n",
        "`/turtle1/cmd_vel` specifies the desired linear and angular velocities for the turtle. `/turtle1/pose` provides the turtle's actual position and orientation in the simulation environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03844bf",
      "metadata": {
        "id": "e03844bf"
      },
      "source": [
        "## Section 1 : Load and Prepare the Training Data\n",
        "We will use the turtlesim example dataset for this tutorial. The dataset is a ROS2 bag file that contains the pose and velocity of a turtle in the turtlesim simulator. The goal is to predict the next pose of the turtle given its current pose and velocity.\n",
        "\n",
        "A config file specifies paths and parameters for the training run. This allows you to easily modify the training setup without changing the code and improves reproducibility. The contents of the config file can then be accessed in the code as a dictionary.  \n",
        "See `config.yaml` for details of the configuration used in this workshop.  \n",
        "\n",
        "The example expects two ROS bag directories in the config:\n",
        "\n",
        "- Training: `rosbag.training_path`  \n",
        "- Evaluation: `rosbag.evaluation_path`  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install and Setup\n",
        "print(\"Cloning workshop repository...\")\n",
        "! [ -d \"ipin2025-workshop\" ] || git clone --quiet https://github.com/flowcean/ipin2025-workshop.git\n",
        "print(\"Installing flowcean...\")\n",
        "! pip install --quiet flowcean==0.7.0b2\n",
        "import os\n",
        "os.chdir(\"ipin2025-workshop\")"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "Ixl6DBC17zKJ"
      },
      "id": "Ixl6DBC17zKJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7a75a6",
      "metadata": {
        "id": "3e7a75a6"
      },
      "outputs": [],
      "source": [
        "import flowcean.cli\n",
        "\n",
        "# The function below looks for a config.yaml in the current directory.\n",
        "# In the config.yaml, we specify settings for our training run\n",
        "config = flowcean.cli.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842384e0",
      "metadata": {
        "id": "842384e0"
      },
      "source": [
        "\n",
        "### Task 1.1 Load Rosbags and Choose Inputs\n",
        "\n",
        "First, we need to load the ROS2 bag file and extract the relevant topics and fields. We will use the `load_rosbag` function from the `flowcean.ros` module to do this.\n",
        "\n",
        "The topics and fields we use load are:   \n",
        "```yaml  \n",
        "  - /turtle1/cmd_vel\n",
        "      - linear.x\n",
        "      - angular.z\n",
        "  - /turtle1/pose\n",
        "      - x\n",
        "      - y\n",
        "      - theta\n",
        "```\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Specify the topics as a dictionary of lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ea77fb",
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "62ea77fb"
      },
      "outputs": [],
      "source": [
        "from flowcean.polars import DataFrame\n",
        "\n",
        "topics = {\n",
        "    \"/turtle1/cmd_vel\": [\n",
        "        \"linear.x\",\n",
        "        \"angular.z\",\n",
        "    ],\n",
        "    \"/turtle1/pose\": [\n",
        "        \"x\",\n",
        "        \"y\",\n",
        "        \"theta\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# show current data structure without transforms\n",
        "rosbag_train = DataFrame.from_rosbag(config.rosbag.training_path, topics=topics)\n",
        "rosbag_eval = DataFrame.from_rosbag(config.rosbag.evaluation_path, topics=topics)\n",
        "print(rosbag_train.observe().collect())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60ecbf8",
      "metadata": {
        "id": "f60ecbf8"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "topics = {\n",
        "    \"/turtle1/cmd_vel\": [\n",
        "        \"linear.x\",\n",
        "        \"angular.z\",\n",
        "    ],\n",
        "    \"/turtle1/pose\": [\n",
        "        \"x\",\n",
        "        \"y\",\n",
        "        \"theta\",\n",
        "    ],\n",
        "}\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c08d81",
      "metadata": {
        "id": "e6c08d81"
      },
      "source": [
        "Note that the current data structure is nested, has only one line and is not yet suitable for training. We will address this in the next tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07f8a7e",
      "metadata": {
        "id": "e07f8a7e"
      },
      "source": [
        "\n",
        "### Task 1.2 Create Training Data Frame\n",
        "\n",
        "Now that we have loaded the ROS2 bag file, we need to create tabular training data that contains the input features and the target variable. The input features are the current pose and velocity of the turtle, and the target variable is the next pose of the turtle.\n",
        "\n",
        "The following table shows how the values of the current pose vector $\\textbf{x}_{k}$ are shifted to form the next pose vector $\\textbf{x}_{k+1}$. The next pose vector is the supervised target we want to predict.\n",
        "\n",
        "| current pose $ \\textbf{x}_{k} $ | velocity command $ \\textbf{u}_{k} $     | next pose $ \\textbf{x}_{k+1} $   |\n",
        "|----------------------|----------------------|----------------------  |\n",
        "| [0, 0, 0]            | [1, 0]               | <span style=\"color:red\">[5, 0, 0]</span>            |\n",
        "| <span style=\"color:red\">[5, 0, 0]</span>          | [0, 1]               | <span style=\"color:green\">[5, 0, 2]</span>          |\n",
        "| <span style=\"color:green\">[5, 0, 2]</span>       | [5, 0]               | [7, 4, 2]            |\n",
        "| ...                    | ...                | ...                    |\n",
        "| [4, 2, 2]     | [0, 0]                | null                    |\n",
        "\n",
        "Note that this results in a null value for the next pose vector in the last row, which is filtered out.\n",
        "We will use the `ZeroOrderHold`, `ExplodeTimeSeries`, and `ShiftInTime` transforms from the `flowcean.polars` module to create the training data frame.\n",
        "You can concatenate/chain transforms to a dataframe with the `|` operator.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Modify the `load_and_process_rosbag` function to create a training data frame with the following steps:\n",
        "- Call the `ZeroOrderHold` Transform:\n",
        "  - our features are our topics\n",
        "  - name the new column \"measurments\"\n",
        "\n",
        "- Use the `|` operator to chain the `ExplodeTimeSeries` Transform: Apply the `ExplodeTimeSeries` transform to the measurement column\n",
        "\n",
        "- Also chain the `ShiftInTime` Transform: Apply the `ShiftInTime` transform to the measurement column\n",
        "  - shift the topics `/turtle1/pose/x`, `/turtle1/pose/y`, `/turtle1/pose/theta` by 1 step and give the new columns the suffix \"_next\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad11fe9",
      "metadata": {
        "id": "2ad11fe9"
      },
      "outputs": [],
      "source": [
        "from _helper_functions import ShiftInTime\n",
        "from flowcean.polars import ExplodeTimeSeries, ZeroOrderHold\n",
        "\n",
        "\n",
        "transforms = None # TODO: Task 1.2\n",
        "\n",
        "\n",
        "# Show the transformed data structure\n",
        "training_environment = rosbag_train | transforms\n",
        "evaluation_environment = rosbag_eval | transforms\n",
        "print(training_environment.observe().collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5103304",
      "metadata": {
        "id": "b5103304"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "transforms = (\n",
        "    ZeroOrderHold(\n",
        "        features=[\n",
        "            \"/turtle1/cmd_vel\",\n",
        "            \"/turtle1/pose\",\n",
        "        ],\n",
        "        name=\"measurements\",\n",
        "    )\n",
        "    | ExplodeTimeSeries(\"measurements\")\n",
        "    | ShiftInTime(\n",
        "        features=[\"/turtle1/pose/x\", \"/turtle1/pose/y\", \"/turtle1/pose/theta\"],\n",
        "        steps=1,\n",
        "        suffix=\"_next\",\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b8eb94",
      "metadata": {
        "id": "96b8eb94"
      },
      "source": [
        "Now we have tabular data with aligned timestamps and separate columns for each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53475c82",
      "metadata": {
        "id": "53475c82"
      },
      "source": [
        "## Section 2 : Select Learners across Libraries\n",
        "\n",
        "Now that we have our training and evaluation samples, we can select learners from different libraries. We will use a `RandomForestRegressor` and a `RegressionTree` from sklearn, a `MultilayerPerceptron` from PyTorch, and an `XGBoostRegressor` from XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f796dd04",
      "metadata": {
        "id": "f796dd04"
      },
      "outputs": [],
      "source": [
        "inputs = [\n",
        "    \"/turtle1/pose/x\",\n",
        "    \"/turtle1/pose/y\",\n",
        "    \"/turtle1/pose/theta\",\n",
        "    \"/turtle1/cmd_vel/linear.x\",\n",
        "    \"/turtle1/cmd_vel/angular.z\",\n",
        "]\n",
        "outputs = [\n",
        "    \"/turtle1/pose/x_next\",\n",
        "    \"/turtle1/pose/y_next\",\n",
        "    \"/turtle1/pose/theta_next\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334c2595",
      "metadata": {
        "id": "334c2595"
      },
      "source": [
        "\n",
        "### Task 2.1 Learner configuration\n",
        "We will use the configurations defined in the `config.yaml` file to initialize our learners. The configurations are stored in the `config.learners` attribute.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Initialize a regression tree, a random forest, a multilayer perceptron, and a XGBoost learner:\n",
        "   - pass the tree configuration to the regression tree\n",
        "   - pass the forest configuration to the random forest\n",
        "   - pass a multilayer perceptron instance to the lightning learner and pass both their respective configurations\n",
        "   - pass a XGBoost regressor instance to the XGBoost learner\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see a hint</summary>\n",
        "    HINT: We defined our configurations in the config.yaml file.                     \n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c18a95",
      "metadata": {
        "id": "89c18a95"
      },
      "outputs": [],
      "source": [
        "from flowcean.sklearn import RandomForestRegressorLearner, RegressionTree\n",
        "from flowcean.torch import LightningLearner, MultilayerPerceptron\n",
        "from flowcean.xgboost import XGBoostRegressorLearner\n",
        "\n",
        "regression_tree = RegressionTree(\n",
        "    max_leaf_nodes=None # TODO: Task 2.1\n",
        ")\n",
        "\n",
        "random_forest = RandomForestRegressorLearner(\n",
        "    n_estimators=None,  # TODO: Task 2.1\n",
        "    max_depth=None,  # TODO: Task 2.1\n",
        ")\n",
        "mlp = LightningLearner(\n",
        "    module=MultilayerPerceptron(\n",
        "        learning_rate=None,  # TODO: Task 2.1\n",
        "        output_size=None,  # TODO: Task 2.1\n",
        "    ),\n",
        "    batch_size=None,  # TODO: Task 2.1\n",
        "    max_epochs=None,  # TODO: Task 2.1\n",
        ")\n",
        "\n",
        "xgb = XGBoostRegressorLearner(\n",
        "    n_estimators=None,  # TODO: Task 2.1\n",
        "    max_depth=None,  # TODO: Task 2.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60be425",
      "metadata": {
        "id": "d60be425"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "regression_tree = RegressionTree(max_leaf_nodes=config.training.tree.max_leaf_nodes)\n",
        "\n",
        "random_forest = RandomForestRegressorLearner(\n",
        "    n_estimators=config.training.forest.n_estimators,\n",
        "    max_depth=config.training.forest.max_depth,\n",
        ")\n",
        "\n",
        "mlp = LightningLearner(\n",
        "    module=MultilayerPerceptron(\n",
        "        learning_rate=config.training.mlp.learning_rate,\n",
        "        output_size=len(outputs),\n",
        "    ),\n",
        "    batch_size=config.training.mlp.batch_size,\n",
        "    max_epochs=config.training.mlp.max_epochs,\n",
        ")\n",
        "\n",
        "xgb = XGBoostRegressorLearner()\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce57354b",
      "metadata": {
        "id": "ce57354b"
      },
      "source": [
        "### Task 2.2 Prepare Sequential Learning\n",
        "We want to train all of our models in a looped fassion. To do this, we need to create a list of our learners.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "   - Create list for the learners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6639e8",
      "metadata": {
        "id": "9c6639e8"
      },
      "outputs": [],
      "source": [
        "learners = [\n",
        "    # TODO: Task 2.2\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a204f6",
      "metadata": {
        "id": "88a204f6"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "learners = [\n",
        "    regression_tree,\n",
        "    random_forest,\n",
        "    mlp,\n",
        "    xgb,\n",
        "]\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cf79f6",
      "metadata": {
        "id": "82cf79f6"
      },
      "source": [
        "## Section 3: Training of the Models\n",
        "\n",
        "We will now train our models by looping over the learners list we created in the previous section and apply the learn_offline strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe91dd18",
      "metadata": {
        "id": "fe91dd18"
      },
      "source": [
        "\n",
        "\n",
        "### Task 3.1 Create a Sequential Learning Loop\n",
        "\n",
        "We will now create a training loop that will train each learner on the training samples. We will store the trained models in a list.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Implement the training loop:\n",
        "  - call the `learn_offline` function and pass the required parameters\n",
        "  - append the trained model to the models list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe0ed37",
      "metadata": {
        "id": "8fe0ed37"
      },
      "outputs": [],
      "source": [
        "from flowcean.core import learn_offline\n",
        "\n",
        "models = []\n",
        "for learner in learners:\n",
        "    print(f\"Training model: {learner.name}\")\n",
        "\n",
        "    model = learn_offline # TODO: Task 2.2\n",
        "\n",
        "    models.append(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9191cfe",
      "metadata": {
        "id": "c9191cfe"
      },
      "source": [
        "\n",
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "  ```python\n",
        "models = []\n",
        "for learner in learners:\n",
        "    print(f\"Training model: {learner.name}\")\n",
        "    model = learn_offline(\n",
        "        training_environment,\n",
        "        learner,\n",
        "        inputs=inputs,\n",
        "        outputs=outputs,\n",
        "    )\n",
        "    models.append(model)\n",
        "\n",
        "  ```\n",
        "  \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5594a375",
      "metadata": {
        "id": "5594a375"
      },
      "source": [
        "## Section 4 : Evaluation and Model Comparison\n",
        "\n",
        "We will now evaluate our trained models on the evaluation environment. We will use the `evaluate_offline` function from the `flowcean.training` module to do this. We will also compare the performance of the models using the `compare_models` function from the same module."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e812e4",
      "metadata": {
        "id": "35e812e4"
      },
      "source": [
        "### Task 4.1 Chose Metrics for Evaluation\n",
        "\n",
        "We want to evaluate our models using different metrics. We will define a list of metrics that we want to use for evaluation. The metrics we want to use are:\n",
        "- Mean Absolute Error\n",
        "- Mean Squared Error\n",
        "- Regression Score (R2Score)\n",
        "- Mean Euclidean Distance\n",
        "\n",
        "**Instructions**   \n",
        "Define a list of metrics that we want to use for evaluation and add the required metrics to a list\n",
        "\n",
        "Note: The euclidean distance requires the features/columns it should be calculated on (`/turtle1/pose/x_next`, `/turtle1/pose/y_next`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07980f90",
      "metadata": {
        "id": "07980f90"
      },
      "outputs": [],
      "source": [
        "from euclidean_distance import MeanEuclideanDistance\n",
        "from flowcean.sklearn import MeanAbsoluteError, MeanSquaredError, R2Score\n",
        "\n",
        "metrics = [\n",
        "    # TODO: 4.1\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a53e30",
      "metadata": {
        "id": "d1a53e30"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "metrics = [\n",
        "    MeanAbsoluteError(),\n",
        "    MeanSquaredError(),\n",
        "    R2Score(),\n",
        "    MeanEuclideanDistance(\n",
        "        features=[\"/turtle1/pose/x_next\", \"/turtle1/pose/y_next\"],\n",
        "    ),\n",
        "]\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de636b99",
      "metadata": {
        "id": "de636b99"
      },
      "source": [
        "### Task 4.2 Create an Evaluation Loop\n",
        "\n",
        "We will use the `evaluate_offline` strategy to evaluate each trained model on the evaluation samples. The resulting report object contains the results of all metrics for each model which can be displayed in a table using the `great_table()` method.\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Implement the evaluation loop:\n",
        "   - call the evaluate_offline function and pass the required parameters\n",
        "   - store the reports in a dict for later comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e2f7eb",
      "metadata": {
        "id": "22e2f7eb"
      },
      "outputs": [],
      "source": [
        "from flowcean.core import evaluate_offline\n",
        "\n",
        "_ = evaluate_offline\n",
        "report = None  # TODO: 4.2\n",
        "report.great_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2d3bd3",
      "metadata": {
        "id": "2b2d3bd3"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see the solution</summary>\n",
        "\n",
        "```python\n",
        "report = evaluate_offline(\n",
        "    models,\n",
        "    environment=evaluation_environment,\n",
        "    metrics=metrics,\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        ")\n",
        "report.great_table()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e674663",
      "metadata": {
        "id": "2e674663"
      },
      "source": [
        "\n",
        "###  Task 4.3 Select a Model and Visualization  \n",
        "\n",
        "We want to select the best model based on the evaluation reports we created in the previous task. We will also visualize the predictions of the best model against the ground truth using the `predictions_vs_ground_truth` function from the same module.\n",
        "\n",
        " **Instructions**\n",
        "\n",
        "   - Choose the best model based on the evaluation report\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18cea52",
      "metadata": {
        "id": "c18cea52"
      },
      "outputs": [],
      "source": [
        "from _helper_functions import plot_predictions_vs_ground_truth\n",
        "\n",
        "best_model = None  # TODO: 4.3\n",
        "print(f\"Best model: {best_model.name}\")\n",
        "\n",
        "# Plots are saved under plots/\n",
        "plot_predictions_vs_ground_truth(\n",
        "    environment=evaluation_environment,\n",
        "    input_names=inputs,\n",
        "    output_names=outputs,\n",
        "    models=models,\n",
        ")\n",
        "\n",
        "# save model to disk\n",
        "best_model.save(\"model.fml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccdf6fc2",
      "metadata": {
        "id": "ccdf6fc2"
      },
      "source": [
        "<details>\n",
        "  <summary>ðŸ’¡ Click to see a solution</summary>\n",
        "\n",
        "The best model is the XGBoost model.\n",
        "\n",
        "\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}